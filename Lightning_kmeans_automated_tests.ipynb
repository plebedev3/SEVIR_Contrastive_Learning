{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Enter path to the SEVIR data location\n",
    "DATA_PATH    = '../../sevir_data_copy/data'\n",
    "CATALOG_PATH = '../../sevir_data_copy/CATALOG.csv' \n",
    "\n",
    "# On some Linux systems setting file locking to false is also necessary:\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"]='FALSE' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py # needs conda/pip install h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipympl --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_event' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e732283bb355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mir069\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ir069'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# plot a frame from each img_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_event' is not defined"
     ]
    }
   ],
   "source": [
    "def read_data( sample_event, img_type, data_path=DATA_PATH ):\n",
    "    \"\"\"\n",
    "    Reads single SEVIR event for a given image type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_event   pd.DataFrame\n",
    "        SEVIR catalog rows matching a single ID\n",
    "    img_type   str\n",
    "        SEVIR image type\n",
    "    data_path  str\n",
    "        Location of SEVIR data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "       LxLx49 tensor containing event data\n",
    "    \"\"\"\n",
    "    fn = sample_event[sample_event.img_type==img_type].squeeze().file_name\n",
    "    fi = sample_event[sample_event.img_type==img_type].squeeze().file_index\n",
    "    with h5py.File(data_path + '/' + fn,'r') as hf:\n",
    "        data=hf[img_type][fi] \n",
    "    return data\n",
    "\n",
    "ir069 = read_data(sample_event, 'ir069')\n",
    "\n",
    "# plot a frame from each img_type\n",
    "fig,axs = plt.subplots(1,1,figsize=(10,5))\n",
    "frame_idx = 30\n",
    "axs.imshow(ir069[:,:,frame_idx]), axs.set_title('IR 6.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as patches\n",
    "from math import sqrt\n",
    "import cv2\n",
    "import h5py # needs conda/pip install h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_data( sample_event, img_type, data_path=DATA_PATH ):\n",
    "    \"\"\"\n",
    "    Reads single SEVIR event for a given image type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_event   pd.DataFrame\n",
    "        SEVIR catalog rows matching a single ID\n",
    "    img_type   str\n",
    "        SEVIR image type\n",
    "    data_path  str\n",
    "        Location of SEVIR data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "       LxLx49 tensor containing event data\n",
    "    \"\"\"\n",
    "    fn = sample_event[sample_event.img_type==img_type].squeeze().file_name\n",
    "    fi = sample_event[sample_event.img_type==img_type].squeeze().file_index\n",
    "    if(type(fn) is not pd.Series):\n",
    "        with h5py.File(data_path + '/' + fn,'r') as hf:\n",
    "            data=hf[img_type][fi] \n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lght_to_grid(data):\n",
    "    \"\"\"\n",
    "    Converts SEVIR lightning data stored in Nx5 matrix to an LxLx49 tensor representing\n",
    "    flash counts per pixel per frame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data  np.array\n",
    "       SEVIR lightning event (Nx5 matrix)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array \n",
    "       LxLx49 tensor containing pixel counts\n",
    "    \"\"\"\n",
    "    FRAME_TIMES = np.arange(-120.0,125.0,5) * 60 # in seconds\n",
    "    out_size = (48,48,len(FRAME_TIMES))\n",
    "    if data.shape[0]==0:\n",
    "        return np.zeros(out_size,dtype=np.float32)\n",
    "\n",
    "    # filter out points outside the grid\n",
    "    x,y=data[:,3],data[:,4]\n",
    "    m=np.logical_and.reduce( [x>=0,x<out_size[0],y>=0,y<out_size[1]] )\n",
    "    data=data[m,:]\n",
    "    if data.shape[0]==0:\n",
    "        return np.zeros(out_size,dtype=np.float32)\n",
    "\n",
    "    # Filter/separate times\n",
    "    # compute z coodinate based on bin locaiton times\n",
    "    t=data[:,0]\n",
    "    z=np.digitize(t,FRAME_TIMES)-1\n",
    "    z[z==-1]=0 # special case:  frame 0 uses lght from frame 1\n",
    "\n",
    "    x=data[:,3].astype(np.int64)\n",
    "    y=data[:,4].astype(np.int64)\n",
    "\n",
    "    k=np.ravel_multi_index(np.array([y,x,z]),out_size)\n",
    "    n = np.bincount(k,minlength=np.prod(out_size))\n",
    "    return np.reshape(n,out_size).astype(np.float32)\n",
    "\n",
    "def read_lght_data( sample_event, data_path=DATA_PATH ):\n",
    "    \"\"\"\n",
    "    Reads lght data from SEVIR and maps flash counts onto a grid  \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_event   pd.DataFrame\n",
    "        SEVIR catalog rows matching a single ID\n",
    "    data_path  str\n",
    "        Location of SEVIR data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array \n",
    "       LxLx49 tensor containing pixel counts for selected event\n",
    "\n",
    "    \"\"\"\n",
    "    fn = sample_event[sample_event.img_type=='lght'].squeeze().file_name\n",
    "    id = sample_event[sample_event.img_type=='lght'].squeeze().id\n",
    "    if(type(fn) is pd.Series):\n",
    "        return None\n",
    "    with h5py.File(data_path + '/' + fn,'r') as hf:\n",
    "        data      = hf[id][:] \n",
    "    return lght_to_grid(data)\n",
    "\n",
    "# Read catalog\n",
    "catalog = pd.read_csv(CATALOG_PATH,parse_dates=['time_utc'],low_memory=False)\n",
    "\n",
    "# Desired image types\n",
    "img_types = set(['vis','ir069','ir107','vil'])\n",
    "\n",
    "# Group by event id, and filter to only events that have all desired img_types\n",
    "events = catalog.groupby('id').filter(lambda x: img_types.issubset(set(x['img_type']))).groupby('id')\n",
    "event_ids = list(events.groups.keys())\n",
    "print('Found %d events matching' % len(event_ids),img_types)\n",
    "\n",
    "#for event_id in event_ids[-15:-10]:\n",
    "def create_lightning_cluster(event_id):\n",
    "    # Grab a sample event and view catalog entries\n",
    "    sample_event = events.get_group(event_id)\n",
    "    #print(event_id)\n",
    "    lght = read_lght_data(sample_event)\n",
    "    ir069 = read_data(sample_event, 'ir069')\n",
    "    if ir069 is None:\n",
    "        return None\n",
    "    if lght is None:\n",
    "        return None\n",
    "    # include lightning counts in plot\n",
    "    #fig,axs = plt.subplots(1,2,figsize=(14,5))\n",
    "    from sklearn.cluster import KMeans\n",
    "    cluster_data = []\n",
    "    rescaled_lightning_imgs = []\n",
    "    for i in range(0,49):\n",
    "        #fig,axs = plt.subplots(1,3,figsize=(14,5))\n",
    "        frame_idx = i\n",
    "        lightning_img = cv2.resize(lght[:,:,frame_idx], (192,192), interpolation=cv2.INTER_NEAREST)\n",
    "#         axs[0].imshow(ir069[:,:,frame_idx]), axs[1].set_title('IR 6.9')\n",
    "#         axs[1].imshow(np.absolute(lght[:,:,frame_idx] - lght[:,:,frame_idx-1])), axs[1].set_title('Lightning Diff')\n",
    "#         axs[2].imshow(lightning_img)\n",
    "        thresh_points = np.argwhere(lightning_img > np.percentile(lightning_img.flatten(), 1)/5)\n",
    "        if(len(thresh_points)==0):\n",
    "            cluster_data.append({})\n",
    "            rescaled_lightning_imgs.append(lightning_img)\n",
    "            continue\n",
    "        #print(optimal_number_of_clusters(thresh_points))\n",
    "        optimal_kmeans = None\n",
    "        optimal_points = 1\n",
    "        for num_cluster_points in range(1,25):\n",
    "            kmeans = KMeans(num_cluster_points, n_init=10,max_iter=300, n_jobs=8)\n",
    "            kmeans.fit(thresh_points)\n",
    "            optimal_kmeans = kmeans\n",
    "            optimal_points = num_cluster_points\n",
    "            if(kmeans.inertia_ <12000):\n",
    "                break\n",
    "        #axs[2].set_title('Lightning with ' + str(optimal_points) +' clusters ')\n",
    "        #print(len(thresh_points))\n",
    "        min_max_dict = {}\n",
    "        for point, label in zip(thresh_points, optimal_kmeans.labels_):\n",
    "            if(label not in min_max_dict.keys()):\n",
    "                min_max_dict[label] = {}\n",
    "                min_max_dict[label][\"count\"] = 1\n",
    "                min_max_dict[label][\"min_x\"] = point[1]\n",
    "                min_max_dict[label][\"max_x\"] = point[1]\n",
    "                min_max_dict[label][\"min_y\"] = point[0]\n",
    "                min_max_dict[label][\"max_y\"] = point[0]\n",
    "                min_max_dict[\"num_clusters\"] = len(optimal_kmeans.labels_)\n",
    "            else:\n",
    "                min_max_dict[label][\"count\"] += 1\n",
    "                if(point[1] < min_max_dict[label][\"min_x\"]):\n",
    "                    min_max_dict[label][\"min_x\"] = point[1]\n",
    "                if(point[0] < min_max_dict[label][\"min_y\"]):\n",
    "                    min_max_dict[label][\"min_y\"] = point[0]\n",
    "                if(point[1] > min_max_dict[label][\"max_x\"]):\n",
    "                    min_max_dict[label][\"max_x\"] = point[1]\n",
    "                if(point[0] > min_max_dict[label][\"max_y\"]):\n",
    "                    min_max_dict[label][\"max_y\"] = point[0]\n",
    "        cluster_data.append(min_max_dict)\n",
    "        rescaled_lightning_imgs.append(lightning_img)\n",
    "    return event_id, ir069, cluster_data, rescaled_lightning_imgs\n",
    "#         for label in range(num_cluster_points):\n",
    "#             start_x, start_y = min_max_dict[label][\"min_x\"], min_max_dict[label][\"min_y\"]\n",
    "#             length_x, length_y = min_max_dict[label][\"max_x\"] - start_x, min_max_dict[label][\"max_y\"] - start_y\n",
    "#             #print((start_x, start_y, length_x, length_y))\n",
    "#             rect = patches.Rectangle((start_x-1, start_y-1),length_x+2,length_y+2,linewidth=1, edgecolor='r',facecolor='none')\n",
    "#             axs[2].add_patch(rect)\n",
    "    \n",
    "        #axs[3].plot(sum_of_squares)\n",
    "    # DIFFERENCES IN LIGHTNING\n",
    "\n",
    "data = Parallel(n_jobs=20)(delayed(create_lightning_cluster)(event_ids[i]) for i in tqdm(range(len(event_ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open(\"cluster_lght_data.pickle\", \"wb\") as pkl_file:\n",
    "import joblib\n",
    "joblib.dump(data, \"cluster_lght_data_2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
